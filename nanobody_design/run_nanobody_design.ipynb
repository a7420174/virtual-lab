{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0a57a439",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a57a439",
        "outputId": "4405379f-4932-4ea7-cf53-509004913301"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ],
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5f709b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5f709b5",
        "outputId": "71cddcd6-b04e-4afb-9a0f-f5bd21b5af04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ],
      "source": [
        "!nohup setsid ollama serve > ollama.log 2>&1 &\n",
        "!ollama pull qwen3:8b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7b8dcf9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7b8dcf9",
        "outputId": "25833b2e-c56b-47be-e569-74626f6a6591"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'virtual-lab'...\n",
            "remote: Enumerating objects: 5108, done.\u001b[K\n",
            "remote: Counting objects: 100% (322/322), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 5108 (delta 259), reused 274 (delta 236), pack-reused 4786 (from 2)\u001b[K\n",
            "Receiving objects: 100% (5108/5108), 37.61 MiB | 19.99 MiB/s, done.\n",
            "Resolving deltas: 100% (2155/2155), done.\n",
            "Obtaining file:///content/virtual-lab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.12/dist-packages (from virtual-lab==1.2.0) (6.5.7)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (from virtual-lab==1.2.0) (2.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from virtual-lab==1.2.0) (2.32.4)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from virtual-lab==1.2.0) (0.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from virtual-lab==1.2.0) (4.67.1)\n",
            "Collecting typed-argument-parser (from virtual-lab==1.2.0)\n",
            "  Downloading typed_argument_parser-1.11.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting biopython (from virtual-lab==1.2.0)\n",
            "  Downloading biopython-1.86-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from virtual-lab==1.2.0) (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from virtual-lab==1.2.0) (0.13.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from virtual-lab==1.2.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from virtual-lab==1.2.0) (4.57.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from biopython->virtual-lab==1.2.0) (2.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from notebook->virtual-lab==1.2.0) (3.1.6)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from notebook->virtual-lab==1.2.0) (6.5.1)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from notebook->virtual-lab==1.2.0) (26.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook->virtual-lab==1.2.0) (25.1.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.12/dist-packages (from notebook->virtual-lab==1.2.0) (5.7.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.12/dist-packages (from notebook->virtual-lab==1.2.0) (5.9.1)\n",
            "Requirement already satisfied: jupyter-client<8,>=5.3.4 in /usr/local/lib/python3.12/dist-packages (from notebook->virtual-lab==1.2.0) (7.4.9)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.12/dist-packages (from notebook->virtual-lab==1.2.0) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from notebook->virtual-lab==1.2.0) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.12/dist-packages (from notebook->virtual-lab==1.2.0) (7.16.6)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.12/dist-packages (from notebook->virtual-lab==1.2.0) (1.6.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from notebook->virtual-lab==1.2.0) (6.17.1)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook->virtual-lab==1.2.0) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook->virtual-lab==1.2.0) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook->virtual-lab==1.2.0) (0.23.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook->virtual-lab==1.2.0) (1.3.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai->virtual-lab==1.2.0) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai->virtual-lab==1.2.0) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai->virtual-lab==1.2.0) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai->virtual-lab==1.2.0) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai->virtual-lab==1.2.0) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai->virtual-lab==1.2.0) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai->virtual-lab==1.2.0) (4.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->virtual-lab==1.2.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->virtual-lab==1.2.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->virtual-lab==1.2.0) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->virtual-lab==1.2.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->virtual-lab==1.2.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->virtual-lab==1.2.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->virtual-lab==1.2.0) (2025.11.12)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.12/dist-packages (from seaborn->virtual-lab==1.2.0) (3.10.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->virtual-lab==1.2.0) (2025.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (3.6.1)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->virtual-lab==1.2.0) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers->virtual-lab==1.2.0) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers->virtual-lab==1.2.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers->virtual-lab==1.2.0) (6.0.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->virtual-lab==1.2.0) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->virtual-lab==1.2.0) (0.7.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from typed-argument-parser->virtual-lab==1.2.0) (0.17.0)\n",
            "Collecting typing-inspect>=0.7.1 (from typed-argument-parser->virtual-lab==1.2.0)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai->virtual-lab==1.2.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->virtual-lab==1.2.0) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->virtual-lab==1.2.0) (1.2.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client<8,>=5.3.4->notebook->virtual-lab==1.2.0) (0.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.6.1->notebook->virtual-lab==1.2.0) (4.5.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->virtual-lab==1.2.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->virtual-lab==1.2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->virtual-lab==1.2.0) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->virtual-lab==1.2.0) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->virtual-lab==1.2.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->virtual-lab==1.2.0) (3.2.5)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from nbclassic>=0.4.7->notebook->virtual-lab==1.2.0) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook->virtual-lab==1.2.0) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook->virtual-lab==1.2.0) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook->virtual-lab==1.2.0) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook->virtual-lab==1.2.0) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook->virtual-lab==1.2.0) (3.0.3)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook->virtual-lab==1.2.0) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook->virtual-lab==1.2.0) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook->virtual-lab==1.2.0) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook->virtual-lab==1.2.0) (2.19.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook->virtual-lab==1.2.0) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook->virtual-lab==1.2.0) (4.25.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai->virtual-lab==1.2.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai->virtual-lab==1.2.0) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai->virtual-lab==1.2.0) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->virtual-lab==1.2.0) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->virtual-lab==1.2.0) (1.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.12/dist-packages (from terminado>=0.8.3->notebook->virtual-lab==1.2.0) (0.7.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.7.1->typed-argument-parser->virtual-lab==1.2.0)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook->virtual-lab==1.2.0) (25.1.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->notebook->virtual-lab==1.2.0) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->notebook->virtual-lab==1.2.0) (7.34.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->notebook->virtual-lab==1.2.0) (0.2.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->notebook->virtual-lab==1.2.0) (5.9.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook->virtual-lab==1.2.0) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook->virtual-lab==1.2.0) (1.4.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->notebook->virtual-lab==1.2.0)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->notebook->virtual-lab==1.2.0) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->notebook->virtual-lab==1.2.0) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->notebook->virtual-lab==1.2.0) (3.0.52)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->notebook->virtual-lab==1.2.0) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->notebook->virtual-lab==1.2.0) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook->virtual-lab==1.2.0) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook->virtual-lab==1.2.0) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook->virtual-lab==1.2.0) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook->virtual-lab==1.2.0) (0.30.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.12/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->virtual-lab==1.2.0) (2.14.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->virtual-lab==1.2.0) (2.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook->virtual-lab==1.2.0) (2.8)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->virtual-lab==1.2.0) (2.23)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->notebook->virtual-lab==1.2.0) (0.8.5)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->virtual-lab==1.2.0) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->virtual-lab==1.2.0) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->virtual-lab==1.2.0) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->virtual-lab==1.2.0) (1.9.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->notebook->virtual-lab==1.2.0) (0.2.14)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->virtual-lab==1.2.0) (4.0.0)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->virtual-lab==1.2.0) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->virtual-lab==1.2.0) (0.1.1)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->virtual-lab==1.2.0) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->virtual-lab==1.2.0) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->virtual-lab==1.2.0) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->virtual-lab==1.2.0) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->virtual-lab==1.2.0) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->virtual-lab==1.2.0) (25.10.0)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->virtual-lab==1.2.0) (1.3.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->virtual-lab==1.2.0) (1.4.0)\n",
            "Downloading biopython-1.86-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typed_argument_parser-1.11.0-py3-none-any.whl (30 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: virtual-lab\n",
            "  Building editable for virtual-lab (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for virtual-lab: filename=virtual_lab-1.2.0-py3-none-any.whl size=4109 sha256=71ea62ea9dbe20592d4f8ba25c2679399679d8e1bd0d17c0a7ae03304ccc99d4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dr3ro5d7/wheels/9b/07/5f/f25da5bedc1be2809caa24ea10c38f1b78be9f12642e5edae0\n",
            "Successfully built virtual-lab\n",
            "Installing collected packages: mypy-extensions, jedi, biopython, typing-inspect, typed-argument-parser, virtual-lab\n",
            "Successfully installed biopython-1.86 jedi-0.19.2 mypy-extensions-1.1.0 typed-argument-parser-1.11.0 typing-inspect-0.9.0 virtual-lab-1.2.0\n",
            "virtual-lab/nanobody_design/install_localcolabfold.sh: line 9: conda: command not found\n",
            "virtual-lab/nanobody_design/install_localcolabfold.sh: line 10: conda: command not found\n",
            "virtual-lab/nanobody_design/install_localcolabfold.sh: line 13: conda: command not found\n",
            "Collecting colabfold@ git+https://github.com/sokrypton/ColabFold (from colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold)\n",
            "  Cloning https://github.com/sokrypton/ColabFold to /tmp/pip-install-wmnpziln/colabfold_eb5b1f8879de4977ae6ae541d65ecfad\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/sokrypton/ColabFold /tmp/pip-install-wmnpziln/colabfold_eb5b1f8879de4977ae6ae541d65ecfad\n",
            "  Resolved https://github.com/sokrypton/ColabFold to commit 83ee93d262a99ad62d6f0897c5ddd37eb918d385\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting appdirs<2.0.0,>=1.4.4 (from colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting biopython<1.86 (from colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold)\n",
            "  Downloading biopython-1.85-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: importlib-metadata<9.0.0,>=8.6.1 in /usr/local/lib/python3.12/dist-packages (from colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (8.7.0)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.8.4 in /usr/local/lib/python3.12/dist-packages (from colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (2.0.2)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.2.2 in /usr/local/lib/python3.12/dist-packages (from colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (2.2.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (2.32.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.62.2 in /usr/local/lib/python3.12/dist-packages (from colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (4.67.1)\n",
            "Requirement already satisfied: absl-py<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (1.4.0)\n",
            "Collecting alphafold-colabfold==2.3.11 (from colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold)\n",
            "  Downloading alphafold_colabfold-2.3.11-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting dm-haiku<0.0.15,>=0.0.14 (from colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold)\n",
            "  Downloading dm_haiku-0.0.14-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: dm-tree<0.2.0,>=0.1.9 in /usr/local/lib/python3.12/dist-packages (from colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (0.1.9)\n",
            "Collecting py3Dmol<3.0.0,>=2.0.1 (from colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold)\n",
            "  Downloading py3dmol-2.5.3-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting tensorflow-cpu<3.0.0,>=2.16.2 (from colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold)\n",
            "  Downloading tensorflow_cpu-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: chex in /usr/local/lib/python3.12/dist-packages (from alphafold-colabfold==2.3.11->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (0.1.90)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.12/dist-packages (from alphafold-colabfold==2.3.11->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (4.2.2)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from alphafold-colabfold==2.3.11->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (0.7.2)\n",
            "Collecting ml-collections (from alphafold-colabfold==2.3.11->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold)\n",
            "  Downloading ml_collections-1.1.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from alphafold-colabfold==2.3.11->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (1.16.3)\n",
            "Collecting jmp>=0.0.2 (from dm-haiku<0.0.15,>=0.0.14->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold)\n",
            "  Downloading jmp-0.0.4-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from dm-haiku<0.0.15,>=0.0.14->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (0.9.0)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.12/dist-packages (from dm-tree<0.2.0,>=0.1.9->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (25.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.12/dist-packages (from dm-tree<0.2.0,>=0.1.9->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (2.0.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<9.0.0,>=8.6.1->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (3.23.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.2.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.2.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.26.0->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.26.0->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.26.0->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.26.0->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (2025.11.12)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (0.7.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (3.4.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (3.2.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (4.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (1.76.0)\n",
            "Collecting tensorboard~=2.20.0 (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold)\n",
            "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (0.18.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (3.1.4)\n",
            "Requirement already satisfied: jaxlib>=0.4.27 in /usr/local/lib/python3.12/dist-packages (from chex->alphafold-colabfold==2.3.11->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (0.7.2)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chex->alphafold-colabfold==2.3.11->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (0.12.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from ml-collections->alphafold-colabfold==2.3.11->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (6.0.3)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold@ git+https://github.com/sokrypton/ColabFold->colabfold[alphafold-minus-jax]@ git+https://github.com/sokrypton/ColabFold) (0.1.2)\n",
            "Downloading alphafold_colabfold-2.3.11-py3-none-any.whl (248 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m248.4/248.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading biopython-1.85-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dm_haiku-0.0.14-py3-none-any.whl (373 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m373.8/373.8 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py3dmol-2.5.3-py2.py3-none-any.whl (7.2 kB)\n",
            "Downloading tensorflow_cpu-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (259.0 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m259.0/259.0 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmp-0.0.4-py3-none-any.whl (18 kB)\n",
            "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_collections-1.1.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: colabfold\n",
            "  Building wheel for colabfold (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colabfold: filename=colabfold-1.5.5-py3-none-any.whl size=78218 sha256=7499b3469fcaefffc134b4df99c8ba0a3c4e921fd29653231f1fb02ae182d84f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-adu6qo7k/wheels/4c/bf/ed/6d891768ab18db868a12995872155b19fadfc3cfeb6a40cbff\n",
            "Successfully built colabfold\n",
            "Installing collected packages: py3Dmol, appdirs, ml-collections, jmp, biopython, tensorboard, dm-haiku, colabfold, tensorflow-cpu, alphafold-colabfold\n",
            "  Attempting uninstall: biopython\n",
            "    Found existing installation: biopython 1.86\n",
            "    Uninstalling biopython-1.86:\n",
            "      Successfully uninstalled biopython-1.86\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.19.0\n",
            "    Uninstalling tensorboard-2.19.0:\n",
            "      Successfully uninstalled tensorboard-2.19.0\n",
            "Successfully installed alphafold-colabfold-2.3.11 appdirs-1.4.4 biopython-1.85 colabfold-1.5.5 dm-haiku-0.0.14 jmp-0.0.4 ml-collections-1.1.0 py3Dmol-2.5.3 tensorboard-2.20.0 tensorflow-cpu-2.20.0\n",
            "Requirement already satisfied: colabfold[alphafold] in /usr/local/lib/python3.12/dist-packages (1.5.5)\n",
            "Requirement already satisfied: absl-py<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from colabfold[alphafold]) (1.4.0)\n",
            "Requirement already satisfied: alphafold-colabfold==2.3.11 in /usr/local/lib/python3.12/dist-packages (from colabfold[alphafold]) (2.3.11)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.4 in /usr/local/lib/python3.12/dist-packages (from colabfold[alphafold]) (1.4.4)\n",
            "Requirement already satisfied: biopython<1.86 in /usr/local/lib/python3.12/dist-packages (from colabfold[alphafold]) (1.85)\n",
            "Requirement already satisfied: dm-haiku<0.0.15,>=0.0.14 in /usr/local/lib/python3.12/dist-packages (from colabfold[alphafold]) (0.0.14)\n",
            "Requirement already satisfied: dm-tree<0.2.0,>=0.1.9 in /usr/local/lib/python3.12/dist-packages (from colabfold[alphafold]) (0.1.9)\n",
            "Requirement already satisfied: importlib-metadata<9.0.0,>=8.6.1 in /usr/local/lib/python3.12/dist-packages (from colabfold[alphafold]) (8.7.0)\n",
            "Collecting jax<0.6.0,>=0.5.2 (from colabfold[alphafold])\n",
            "  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.8.4 in /usr/local/lib/python3.12/dist-packages (from colabfold[alphafold]) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from colabfold[alphafold]) (2.0.2)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.2.2 in /usr/local/lib/python3.12/dist-packages (from colabfold[alphafold]) (2.2.2)\n",
            "Requirement already satisfied: py3Dmol<3.0.0,>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from colabfold[alphafold]) (2.5.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from colabfold[alphafold]) (2.32.4)\n",
            "Requirement already satisfied: tensorflow-cpu<3.0.0,>=2.16.2 in /usr/local/lib/python3.12/dist-packages (from colabfold[alphafold]) (2.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.62.2 in /usr/local/lib/python3.12/dist-packages (from colabfold[alphafold]) (4.67.1)\n",
            "Requirement already satisfied: chex in /usr/local/lib/python3.12/dist-packages (from alphafold-colabfold==2.3.11->colabfold[alphafold]) (0.1.90)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.12/dist-packages (from alphafold-colabfold==2.3.11->colabfold[alphafold]) (4.2.2)\n",
            "Requirement already satisfied: ml-collections in /usr/local/lib/python3.12/dist-packages (from alphafold-colabfold==2.3.11->colabfold[alphafold]) (1.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from alphafold-colabfold==2.3.11->colabfold[alphafold]) (1.16.3)\n",
            "Requirement already satisfied: jmp>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from dm-haiku<0.0.15,>=0.0.14->colabfold[alphafold]) (0.0.4)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from dm-haiku<0.0.15,>=0.0.14->colabfold[alphafold]) (0.9.0)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.12/dist-packages (from dm-tree<0.2.0,>=0.1.9->colabfold[alphafold]) (25.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.12/dist-packages (from dm-tree<0.2.0,>=0.1.9->colabfold[alphafold]) (2.0.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<9.0.0,>=8.6.1->colabfold[alphafold]) (3.23.0)\n",
            "Collecting jaxlib<=0.5.3,>=0.5.3 (from jax<0.6.0,>=0.5.2->colabfold[alphafold])\n",
            "  Downloading jaxlib-0.5.3-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from jax<0.6.0,>=0.5.2->colabfold[alphafold]) (0.5.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax<0.6.0,>=0.5.2->colabfold[alphafold]) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->colabfold[alphafold]) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->colabfold[alphafold]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->colabfold[alphafold]) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->colabfold[alphafold]) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->colabfold[alphafold]) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->colabfold[alphafold]) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->colabfold[alphafold]) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->colabfold[alphafold]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.2.2->colabfold[alphafold]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.2.2->colabfold[alphafold]) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.26.0->colabfold[alphafold]) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.26.0->colabfold[alphafold]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.26.0->colabfold[alphafold]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.26.0->colabfold[alphafold]) (2025.11.12)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (0.7.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (18.1.1)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (3.2.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (4.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (3.15.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (0.18.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (3.1.4)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chex->alphafold-colabfold==2.3.11->colabfold[alphafold]) (0.12.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from ml-collections->alphafold-colabfold==2.3.11->colabfold[alphafold]) (6.0.3)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow-cpu<3.0.0,>=2.16.2->colabfold[alphafold]) (0.1.2)\n",
            "Downloading jax-0.5.3-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.5.3-cp312-cp312-manylinux2014_x86_64.whl (105.1 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m105.1/105.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jaxlib, jax\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.7.2\n",
            "    Uninstalling jaxlib-0.7.2:\n",
            "      Successfully uninstalled jaxlib-0.7.2\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.7.2\n",
            "    Uninstalling jax-0.7.2:\n",
            "      Successfully uninstalled jax-0.7.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "orbax-checkpoint 0.11.31 requires jax>=0.6.0, but you have jax 0.5.3 which is incompatible.\n",
            "flax 0.10.7 requires jax>=0.6.0, but you have jax 0.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jax-0.5.3 jaxlib-0.5.3\n",
            "Collecting jax==0.4.28 (from jax[cuda12]==0.4.28)\n",
            "  Downloading jax-0.4.28-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from jax==0.4.28->jax[cuda12]==0.4.28) (0.5.4)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from jax==0.4.28->jax[cuda12]==0.4.28) (2.0.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.12/dist-packages (from jax==0.4.28->jax[cuda12]==0.4.28) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.12/dist-packages (from jax==0.4.28->jax[cuda12]==0.4.28) (1.16.3)\n",
            "Collecting jaxlib==0.4.28 (from jax[cuda12]==0.4.28)\n",
            "  Downloading jaxlib-0.4.28-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting jax-cuda12-plugin==0.4.28 (from jax[cuda12]==0.4.28)\n",
            "  Downloading jax_cuda12_plugin-0.4.28-cp312-cp312-manylinux2014_x86_64.whl.metadata (560 bytes)\n",
            "Requirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12]==0.4.28) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12>=12.1.105 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12]==0.4.28) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cuda-nvcc-cu12>=12.1.105 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12]==0.4.28) (12.5.82)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12]==0.4.28) (12.6.77)\n",
            "Collecting nvidia-cudnn-cu12<9.0,>=8.9.2.26 (from jax[cuda12]==0.4.28)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cufft-cu12>=11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12]==0.4.28) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12>=11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12]==0.4.28) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12>=12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12]==0.4.28) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12>=2.18.1 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12]==0.4.28) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12>=12.1.105 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12]==0.4.28) (12.6.85)\n",
            "Collecting jax-cuda12-pjrt==0.4.28 (from jax-cuda12-plugin==0.4.28->jax[cuda12]==0.4.28)\n",
            "  Downloading jax_cuda12_pjrt-0.4.28-py3-none-manylinux2014_x86_64.whl.metadata (349 bytes)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cudnn-cu12<9.0,>=8.9.2.26->jax[cuda12]==0.4.28) (12.6.77)\n",
            "Downloading jax-0.4.28-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax_cuda12_plugin-0.4.28-cp312-cp312-manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.4.28-cp312-cp312-manylinux2014_x86_64.whl (77.6 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m77.6/77.6 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax_cuda12_pjrt-0.4.28-py3-none-manylinux2014_x86_64.whl (86.8 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m86.8/86.8 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl (704.7 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m704.7/704.7 MB\u001b[0m \u001b[31m725.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jax-cuda12-pjrt, nvidia-cudnn-cu12, jax-cuda12-plugin, jaxlib, jax\n",
            "  Attempting uninstall: jax-cuda12-pjrt\n",
            "    Found existing installation: jax-cuda12-pjrt 0.7.2\n",
            "    Uninstalling jax-cuda12-pjrt-0.7.2:\n",
            "      Successfully uninstalled jax-cuda12-pjrt-0.7.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: jax-cuda12-plugin\n",
            "    Found existing installation: jax-cuda12-plugin 0.7.2\n",
            "    Uninstalling jax-cuda12-plugin-0.7.2:\n",
            "      Successfully uninstalled jax-cuda12-plugin-0.7.2\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.5.3\n",
            "    Uninstalling jaxlib-0.5.3:\n",
            "      Successfully uninstalled jaxlib-0.5.3\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.5.3\n",
            "    Uninstalling jax-0.5.3:\n",
            "      Successfully uninstalled jax-0.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "optax 0.2.6 requires jax>=0.5.3, but you have jax 0.4.28 which is incompatible.\n",
            "optax 0.2.6 requires jaxlib>=0.5.3, but you have jaxlib 0.4.28 which is incompatible.\n",
            "torch 2.9.0+cu126 requires nvidia-cudnn-cu12==9.10.2.21; platform_system == \"Linux\", but you have nvidia-cudnn-cu12 8.9.7.29 which is incompatible.\n",
            "orbax-checkpoint 0.11.31 requires jax>=0.6.0, but you have jax 0.4.28 which is incompatible.\n",
            "flax 0.10.7 requires jax>=0.6.0, but you have jax 0.4.28 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jax-0.4.28 jax-cuda12-pjrt-0.4.28 jax-cuda12-plugin-0.4.28 jaxlib-0.4.28 nvidia-cudnn-cu12-8.9.7.29\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.1.4)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.19.0\n",
            "    Uninstalling tensorflow-2.19.0:\n",
            "      Successfully uninstalled tensorflow-2.19.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.20.0 which is incompatible.\n",
            "tf-keras 2.19.0 requires tensorflow<2.20,>=2.19, but you have tensorflow 2.20.0 which is incompatible.\n",
            "tensorflow-text 2.19.0 requires tensorflow<2.20,>=2.19.0, but you have tensorflow 2.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorflow-2.20.0\n",
            "Collecting silence_tensorflow\n",
            "  Downloading silence_tensorflow-1.2.3.tar.gz (7.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: silence_tensorflow\n",
            "  Building wheel for silence_tensorflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for silence_tensorflow: filename=silence_tensorflow-1.2.3-py3-none-any.whl size=6749 sha256=e484b86f068be615a6e5a9bd04324dca4b87f0b38ce4bada3b18d71911d50b4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/72/a8/c82c307e9ea240ed4edccfee66ea134a497126cdf5fc7f03d4\n",
            "Successfully built silence_tensorflow\n",
            "Installing collected packages: silence_tensorflow\n",
            "Successfully installed silence_tensorflow-1.2.3\n",
            "virtual-lab/nanobody_design/install_localcolabfold.sh: line 24: conda: command not found\n",
            "virtual-lab/nanobody_design/install_localcolabfold.sh: line 24: pushd: /envs/localcolabfold/lib/python3.10/site-packages/colabfold: No such file or directory\n",
            "sed: can't read plot.py: No such file or directory\n",
            "sed: can't read download.py: No such file or directory\n",
            "sed: can't read batch.py: No such file or directory\n",
            "virtual-lab/nanobody_design/install_localcolabfold.sh: line 33: popd: directory stack empty\n",
            "Downloading alphafold2_multimer_v3 weights to /root/.cache/colabfold:   0% 0/4099624960 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/colabfold/download.py:85: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  file.extractall(path=params_dir)\n",
            "Downloading alphafold2_multimer_v3 weights to /root/.cache/colabfold: 100% 3.82G/3.82G [00:22<00:00, 186MB/s]\n",
            "Downloading AlphaFold2-ptm weights to /root/.cache/colabfold: 100% 3.47G/3.47G [00:17<00:00, 214MB/s]\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/a7420174/virtual-lab.git\n",
        "!cd virtual-lab && pip install -e .[nanobody-design]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e301a638",
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -qO- https://raw.githubusercontent.com/YoshitakaMo/localcolabfold/main/install_colabbatch_linux.sh | bash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8b39d57",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=/content/localcolabfold/colabfold-conda/bin:$PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "initial_id",
        "outputId": "68a90969-2606-4b94-a981-f642523e6c3b"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'virtual_lab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1963009278.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvirtual_lab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCONSISTENT_TEMPERATURE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCREATIVE_TEMPERATURE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m from virtual_lab.prompts import (\n\u001b[1;32m      7\u001b[0m     \u001b[0mCODING_RULES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'virtual_lab'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import concurrent.futures\n",
        "import os, sys, json\n",
        "from pathlib import Path\n",
        "\n",
        "if not \"/content/virtual-lab/src/\" in sys.path:\n",
        "  sys.path.append(\"/content/virtual-lab/src/\")\n",
        "if not \"/content/virtual-lab/nanobody_design/\" in sys.path:\n",
        "  sys.path.append(\"/content/virtual-lab/nanobody_design/\")\n",
        "\n",
        "os.environ[\"OPENAI_BASE_URL\"] = \"http://localhost:11434/v1\"\n",
        "\n",
        "\n",
        "from virtual_lab.constants import CONSISTENT_TEMPERATURE, CREATIVE_TEMPERATURE\n",
        "from virtual_lab.prompts import (\n",
        "    CODING_RULES,\n",
        "    REWRITE_PROMPT,\n",
        "    create_merge_prompt,\n",
        ")\n",
        "from virtual_lab.run_meeting import run_meeting\n",
        "from virtual_lab.utils import load_summaries\n",
        "\n",
        "from nanobody_constants import (\n",
        "    background_prompt,\n",
        "    nanobody_prompt,\n",
        "    num_iterations,\n",
        "    num_rounds,\n",
        "    discussions_phase_to_dir,\n",
        "    principal_investigator,\n",
        "    team_members,\n",
        "    machine_learning_specialist,\n",
        "    computational_biologist,\n",
        "    scientific_critic\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9259ddc2710488f",
      "metadata": {
        "id": "a9259ddc2710488f"
      },
      "source": [
        "## Team selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c55d79aa92e377b5",
      "metadata": {
        "id": "c55d79aa92e377b5"
      },
      "outputs": [],
      "source": [
        "# Team selection - prompts\n",
        "team_selection_agenda = f\"\"\"{background_prompt} You need to select a team of three scientists to help you with this project. Please select the team members that you would like to invite to a discussion to create the antibody/nanobody design approach. Please list the team members in the following format, using the team member below as an example. You should not include yourself (Principal Investigator) in the list.\n",
        "\n",
        "Agent(\n",
        "    title=\"Principal Investigator\",\n",
        "    expertise=\"applying artificial intelligence to biomedical research\",\n",
        "    goal=\"perform research in your area of expertise that maximizes the scientific impact of the work\",\n",
        "    role=\"lead a team of experts to solve an important problem in artificial intelligence for biomedicine, make key decisions about the project direction based on team member input, and manage the project timeline and resources\",\n",
        ")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50722e4dadc135d8",
      "metadata": {
        "id": "50722e4dadc135d8"
      },
      "outputs": [],
      "source": [
        "# Team selection - discussion\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    concurrent.futures.wait([\n",
        "        executor.submit(\n",
        "            run_meeting,\n",
        "            meeting_type=\"individual\",\n",
        "            team_member=principal_investigator,\n",
        "            agenda=team_selection_agenda,\n",
        "            save_dir=discussions_phase_to_dir[\"team_selection\"],\n",
        "            save_name=f\"discussion_{iteration_num + 1}\",\n",
        "            temperature=CREATIVE_TEMPERATURE,\n",
        "        ) for iteration_num in range(num_iterations)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1c023cebeaaf883",
      "metadata": {
        "id": "f1c023cebeaaf883"
      },
      "outputs": [],
      "source": [
        "# Team selection - merge\n",
        "team_selection_summaries = load_summaries(\n",
        "    discussion_paths=list(discussions_phase_to_dir[\"team_selection\"].glob(\"discussion_*.json\")))\n",
        "print(f\"Number of summaries: {len(team_selection_summaries)}\")\n",
        "\n",
        "team_selection_merge_prompt = create_merge_prompt(agenda=team_selection_agenda)\n",
        "\n",
        "run_meeting(\n",
        "    meeting_type=\"individual\",\n",
        "    team_member=principal_investigator,\n",
        "    summaries=team_selection_summaries,\n",
        "    agenda=team_selection_merge_prompt,\n",
        "    save_dir=discussions_phase_to_dir[\"team_selection\"],\n",
        "    save_name=\"merged\",\n",
        "    temperature=CONSISTENT_TEMPERATURE,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3804141d0b26537",
      "metadata": {
        "id": "3804141d0b26537"
      },
      "source": [
        "## Projects specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9df84a9e45d31bbe",
      "metadata": {
        "id": "9df84a9e45d31bbe"
      },
      "outputs": [],
      "source": [
        "# Project specification - prompts\n",
        "project_specification_agenda = f\"{background_prompt} Please create an antibody/nanobody design approach to solve this problem. Decide whether you will design antibodies or nanobodies. For your choice, decide whether you will design the antibodies/nanobodies de novo or whether you will modify existing antibodies/nanobodies. If modifying existing antibodies/nanobodies, please specify which antibodies/nanobodies to start with as good candidates for targeting the newest variant of the SARS-CoV-2 spike protein. If designing antibodies/nanobodies de novo, please describe how you will propose antibody/nanobody candidates.\"\n",
        "\n",
        "project_specification_questions = (\n",
        "    \"Will you design standard antibodies or nanobodies?\",\n",
        "    \"Will you design antibodies/nanobodies de novo or will you modify existing antibodies/nanobodies (choose only one)?\",\n",
        "    \"If modifying existing antibodies/nanobodies, which precise antibodies/nanobodies will you modify (please list 3-4)?\",\n",
        "    \"If designing antibodies/nanobodies de novo, how exactly will you propose antibody/nanobody candidates?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ff509ba8824b8ac",
      "metadata": {
        "id": "9ff509ba8824b8ac"
      },
      "outputs": [],
      "source": [
        "# Project specification - discussion\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    concurrent.futures.wait([\n",
        "        executor.submit(\n",
        "            run_meeting,\n",
        "            meeting_type=\"team\",\n",
        "            team_lead=principal_investigator,\n",
        "            team_members=team_members,\n",
        "            agenda=project_specification_agenda,\n",
        "            agenda_questions=project_specification_questions,\n",
        "            save_dir=discussions_phase_to_dir[\"project_specification\"],\n",
        "            save_name=f\"discussion_{iteration_num + 1}\",\n",
        "            temperature=CREATIVE_TEMPERATURE,\n",
        "            num_rounds=num_rounds,\n",
        "        ) for iteration_num in range(num_iterations)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e66e0cfa85f2176d",
      "metadata": {
        "id": "e66e0cfa85f2176d"
      },
      "outputs": [],
      "source": [
        "# Project specification - merge\n",
        "project_specification_summaries = load_summaries(\n",
        "    discussion_paths=list(discussions_phase_to_dir[\"project_specification\"].glob(\"discussion_*.json\")))\n",
        "print(f\"Number of summaries: {len(project_specification_summaries)}\")\n",
        "\n",
        "project_specification_merge_prompt = create_merge_prompt(\n",
        "    agenda=project_specification_agenda,\n",
        "    agenda_questions=project_specification_questions,\n",
        ")\n",
        "\n",
        "run_meeting(\n",
        "    meeting_type=\"individual\",\n",
        "    team_member=principal_investigator,\n",
        "    summaries=project_specification_summaries,\n",
        "    agenda=project_specification_merge_prompt,\n",
        "    save_dir=discussions_phase_to_dir[\"project_specification\"],\n",
        "    save_name=\"merged\",\n",
        "    temperature=CONSISTENT_TEMPERATURE,\n",
        "    num_rounds=num_rounds,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e5307d354d28011",
      "metadata": {
        "id": "7e5307d354d28011"
      },
      "source": [
        "## Tools Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a001a2ca1ea13a4c",
      "metadata": {
        "id": "a001a2ca1ea13a4c"
      },
      "outputs": [],
      "source": [
        "# Tools selection - prompts\n",
        "tools_selection_agenda = f\"{background_prompt} {nanobody_prompt} Now you need to select machine learning and/or computational tools to implement this nanobody design approach. Please list several tools (5-10) that would be relevant to this nanobody design approach and how they could be used in the context of this project. If selecting machine learning tools, please prioritize pre-trained models (e.g., pre-trained protein language models or protein structure prediction models) for simplicity.\"\n",
        "\n",
        "tools_selection_questions = (\n",
        "    \"What machine learning and/or computational tools could be used for this nanobody design approach (list 5-10)?\",\n",
        "    \"For each tool, how could it be used for designing modified nanobodies?\",\n",
        ")\n",
        "\n",
        "tools_selection_prior_summaries = load_summaries(\n",
        "    discussion_paths=[discussions_phase_to_dir[\"project_specification\"] / \"merged.json\"])\n",
        "print(f\"Number of prior summaries: {len(tools_selection_prior_summaries)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a95de22d2f1d277b",
      "metadata": {
        "id": "a95de22d2f1d277b"
      },
      "outputs": [],
      "source": [
        "# Tools selection - discussion\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    concurrent.futures.wait([\n",
        "        executor.submit(\n",
        "            run_meeting,\n",
        "            meeting_type=\"team\",\n",
        "            team_lead=principal_investigator,\n",
        "            team_members=team_members,\n",
        "            summaries=tools_selection_prior_summaries,\n",
        "            agenda=tools_selection_agenda,\n",
        "            agenda_questions=tools_selection_questions,\n",
        "            save_dir=discussions_phase_to_dir[\"tools_selection\"],\n",
        "            save_name=f\"discussion_{iteration_num + 1}\",\n",
        "            temperature=CREATIVE_TEMPERATURE,\n",
        "            num_rounds=num_rounds,\n",
        "        ) for iteration_num in range(num_iterations)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "580378a119b0cce5",
      "metadata": {
        "id": "580378a119b0cce5"
      },
      "outputs": [],
      "source": [
        "# Tools selection - merge\n",
        "tools_selection_summaries = load_summaries(\n",
        "    discussion_paths=list(discussions_phase_to_dir[\"tools_selection\"].glob(\"discussion_*.json\")))\n",
        "print(f\"Number of summaries: {len(tools_selection_summaries)}\")\n",
        "\n",
        "tools_selection_merge_prompt = create_merge_prompt(\n",
        "    agenda=tools_selection_agenda,\n",
        "    agenda_questions=tools_selection_questions,\n",
        ")\n",
        "\n",
        "run_meeting(\n",
        "    meeting_type=\"individual\",\n",
        "    team_member=principal_investigator,\n",
        "    summaries=tools_selection_summaries,\n",
        "    agenda=tools_selection_merge_prompt,\n",
        "    save_dir=discussions_phase_to_dir[\"tools_selection\"],\n",
        "    save_name=\"merged\",\n",
        "    temperature=CONSISTENT_TEMPERATURE,\n",
        "    num_rounds=num_rounds,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3777aacd05e6e17",
      "metadata": {
        "id": "c3777aacd05e6e17"
      },
      "source": [
        "## Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4b45d33467d1405",
      "metadata": {
        "id": "a4b45d33467d1405"
      },
      "outputs": [],
      "source": [
        "# Implementation - prompts\n",
        "implementation_agent_selection_agenda = f\"{background_prompt} {nanobody_prompt} Your team needs to build three components of a nanobody design pipeline: ESM, AlphaFold-Multimer, and Rosetta. For each component, please select the team member who will implement the component. A team member may implement more than one component.\"\n",
        "\n",
        "implementation_agent_selection_questions = (\n",
        "    \"Which team member will implement ESM?\",\n",
        "    \"Which team member will implement AlphaFold-Multimer?\",\n",
        "    \"Which team member will implement Rosetta?\",\n",
        ")\n",
        "\n",
        "implementation_agent_selection_prior_summaries = load_summaries(\n",
        "    discussion_paths=[discussions_phase_to_dir[\"team_selection\"] / \"merged.json\",\n",
        "                      discussions_phase_to_dir[\"project_specification\"] / \"merged.json\",\n",
        "                      discussions_phase_to_dir[\"tools_selection\"] / \"merged.json\"])\n",
        "print(f\"Number of prior summaries: {len(implementation_agent_selection_prior_summaries)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "777c7f17e1853145",
      "metadata": {
        "id": "777c7f17e1853145"
      },
      "outputs": [],
      "source": [
        "# Implementation - discussion\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    concurrent.futures.wait([\n",
        "        executor.submit(\n",
        "            run_meeting,\n",
        "            meeting_type=\"individual\",\n",
        "            team_member=principal_investigator,\n",
        "            summaries=implementation_agent_selection_prior_summaries,\n",
        "            agenda=implementation_agent_selection_agenda,\n",
        "            agenda_questions=implementation_agent_selection_questions,\n",
        "            save_dir=discussions_phase_to_dir[\"implementation_agent_selection\"],\n",
        "            save_name=f\"discussion_{iteration_num + 1}\",\n",
        "            temperature=CREATIVE_TEMPERATURE,\n",
        "        ) for iteration_num in range(num_iterations)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b741ab035e21003c",
      "metadata": {
        "id": "b741ab035e21003c"
      },
      "outputs": [],
      "source": [
        "# Implementation - merge\n",
        "implementation_agent_selection_summaries = load_summaries(\n",
        "    discussion_paths=list(discussions_phase_to_dir[\"implementation_agent_selection\"].glob(\"discussion_*.json\")))\n",
        "print(f\"Number of summaries: {len(implementation_agent_selection_summaries)}\")\n",
        "\n",
        "implementation_agent_selection_merge_prompt = create_merge_prompt(\n",
        "    agenda=implementation_agent_selection_agenda,\n",
        "    agenda_questions=implementation_agent_selection_questions\n",
        ")\n",
        "\n",
        "run_meeting(\n",
        "    meeting_type=\"individual\",\n",
        "    team_member=principal_investigator,\n",
        "    summaries=implementation_agent_selection_summaries,\n",
        "    agenda=implementation_agent_selection_merge_prompt,\n",
        "    save_dir=discussions_phase_to_dir[\"implementation_agent_selection\"],\n",
        "    save_name=\"merged\",\n",
        "    temperature=CONSISTENT_TEMPERATURE,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b1ac62cf9a8f39",
      "metadata": {
        "id": "9b1ac62cf9a8f39"
      },
      "source": [
        "### ESM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b2b6e3a180a548e",
      "metadata": {
        "id": "1b2b6e3a180a548e"
      },
      "outputs": [],
      "source": [
        "# ESM - prompts\n",
        "esm_agenda = f\"{background_prompt} {nanobody_prompt} Now you must use ESM to suggest modifications to an existing antibody. Please write a complete Python script that takes a nanobody sequence as input and uses ESM amino acid log-likelihoods to identify the most promising point mutations by log-likelihood ratio.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0affb5cd00bec96",
      "metadata": {
        "id": "e0affb5cd00bec96"
      },
      "outputs": [],
      "source": [
        "# ESM - discussion\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    concurrent.futures.wait([\n",
        "        executor.submit(\n",
        "            run_meeting,\n",
        "            meeting_type=\"individual\",\n",
        "            team_member=machine_learning_specialist,\n",
        "            agenda=esm_agenda,\n",
        "            agenda_rules=CODING_RULES,\n",
        "            save_dir=discussions_phase_to_dir[\"esm\"],\n",
        "            save_name=f\"discussion_{iteration_num + 1}\",\n",
        "            temperature=CREATIVE_TEMPERATURE,\n",
        "            num_rounds=num_rounds,\n",
        "        ) for iteration_num in range(num_iterations)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b0936e225dcc32f",
      "metadata": {
        "id": "6b0936e225dcc32f"
      },
      "outputs": [],
      "source": [
        "# ESM - merge\n",
        "esm_summaries = load_summaries(discussion_paths=list(discussions_phase_to_dir[\"esm\"].glob(\"discussion_*.json\")))\n",
        "print(f\"Number of summaries: {len(esm_summaries)}\")\n",
        "\n",
        "esm_merge_prompt = create_merge_prompt(\n",
        "    agenda=esm_agenda,\n",
        "    agenda_rules=CODING_RULES,\n",
        ")\n",
        "\n",
        "run_meeting(\n",
        "    meeting_type=\"individual\",\n",
        "    team_member=machine_learning_specialist,\n",
        "    summaries=esm_summaries,\n",
        "    agenda=esm_merge_prompt,\n",
        "    save_dir=discussions_phase_to_dir[\"esm\"],\n",
        "    save_name=\"merged\",\n",
        "    temperature=CONSISTENT_TEMPERATURE,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cf7a7a3d2b7b7fe",
      "metadata": {
        "id": "9cf7a7a3d2b7b7fe"
      },
      "source": [
        "### Improve ESM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b062e9cb5f92a482",
      "metadata": {
        "id": "b062e9cb5f92a482"
      },
      "outputs": [],
      "source": [
        "# Improve ESM - prompts\n",
        "improve_esm_agenda = f\"\"\"You previously wrote a Python script that uses ESM to compute the log-likelihood ratio of point mutations in a nanobody sequence (see summary). {REWRITE_PROMPT}\n",
        "\n",
        "1. Replace \"facebook/esm1b-t33_650M_UR50S\" with \"facebook/esm1b_t33_650M_UR50S\".\n",
        "2. Run the calculations of the mutant log-likelihoods by iterating through the sequences in batches of 16.\n",
        "3. Add a progress bar to the batched mutant log-likelihood calculations.\n",
        "4. Run the mutant log-likelihood calculations on CUDA but with no gradients.\n",
        "5. Load the nanobody sequence from a user-specified CSV file that has the columns \"sequence\" and \"name\". Adapt your code to run the mutant log-likelihood calculations on all sequences in the CSV file one-by-one.\n",
        "6. For each sequence, save the mutant log-likelihoods to a CSV file with the format \"mutated_sequence,position,original_aa,mutated_aa,log_likelihood_ratio\". Ask the user for a save directory and then save this CSV file in that directory with the name: <nanbody-name>.csv.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6388c95f9e77d811",
      "metadata": {
        "id": "6388c95f9e77d811"
      },
      "outputs": [],
      "source": [
        "# Improve ESM - discussion\n",
        "improve_esm_summaries = load_summaries(discussion_paths=[discussions_phase_to_dir[\"esm\"] / \"merged.json\"])\n",
        "print(f\"Number of summaries: {len(improve_esm_summaries)}\")\n",
        "\n",
        "run_meeting(\n",
        "    meeting_type=\"individual\",\n",
        "    team_member=machine_learning_specialist,\n",
        "    summaries=improve_esm_summaries,\n",
        "    agenda=improve_esm_agenda,\n",
        "    save_dir=discussions_phase_to_dir[\"esm\"],\n",
        "    save_name=\"improved\",\n",
        "    temperature=CONSISTENT_TEMPERATURE,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ba22302ea18a575",
      "metadata": {
        "id": "9ba22302ea18a575"
      },
      "source": [
        "### AlphaFold-Multimer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9588993af806c3f1",
      "metadata": {
        "id": "9588993af806c3f1"
      },
      "outputs": [],
      "source": [
        "# AlphaFold-Multimer - prompts\n",
        "alphafold_agenda = f\"{background_prompt} {nanobody_prompt} Now you must use AlphaFold-Multimer to predict the structure of a nanobody-antigen complex and evaluate its binding. I will run AlphaFold-Multimer on several nanobody-antigen complexes and you need to process the outputs. Please write a complete Python script that takes as input a directory containing PDB files where each PDB file contains one nanobody-antigen complex predicted by AlphaFold-Multimer and outputs a CSV file containing the AlphaFold-Multimer confidence of each nanobody-antigen complex in terms of the interface pLDDT.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ca49b4e29ac8b6a",
      "metadata": {
        "id": "1ca49b4e29ac8b6a"
      },
      "outputs": [],
      "source": [
        "# AlphaFold-Multimer - discussion\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    concurrent.futures.wait([\n",
        "        executor.submit(\n",
        "            run_meeting,\n",
        "            meeting_type=\"individual\",\n",
        "            team_member=computational_biologist,\n",
        "            agenda=alphafold_agenda,\n",
        "            agenda_rules=CODING_RULES,\n",
        "            save_dir=discussions_phase_to_dir[\"alphafold\"],\n",
        "            save_name=f\"discussion_{iteration_num + 1}\",\n",
        "            temperature=CREATIVE_TEMPERATURE,\n",
        "            num_rounds=num_rounds,\n",
        "        ) for iteration_num in range(num_iterations)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d03e25b1ecad9557",
      "metadata": {
        "id": "d03e25b1ecad9557"
      },
      "outputs": [],
      "source": [
        "# AlphaFold-Multimer - merge\n",
        "alphafold_summaries = load_summaries(\n",
        "    discussion_paths=list(discussions_phase_to_dir[\"alphafold\"].glob(\"discussion_*.json\")))\n",
        "print(f\"Number of summaries: {len(alphafold_summaries)}\")\n",
        "\n",
        "alphafold_merge_prompt = create_merge_prompt(\n",
        "    agenda=alphafold_agenda,\n",
        "    agenda_rules=CODING_RULES,\n",
        ")\n",
        "\n",
        "run_meeting(\n",
        "    meeting_type=\"individual\",\n",
        "    team_member=computational_biologist,\n",
        "    summaries=alphafold_summaries,\n",
        "    agenda=alphafold_merge_prompt,\n",
        "    save_dir=discussions_phase_to_dir[\"alphafold\"],\n",
        "    save_name=\"merged\",\n",
        "    temperature=CONSISTENT_TEMPERATURE,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "619858f6ff3335c6",
      "metadata": {
        "id": "619858f6ff3335c6"
      },
      "source": [
        "### Improve AlphaFold-Multimer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd78a537e8608abb",
      "metadata": {
        "id": "dd78a537e8608abb"
      },
      "outputs": [],
      "source": [
        "# Improve AlphaFold-Multimer - prompts\n",
        "improve_alphafold_agenda = f\"\"\"You previously wrote a Python script that processes the outputs of AlphaFold-Multimer to calculate the confidence of nanobody-antigen complexes (see summary). {REWRITE_PROMPT}\n",
        "\n",
        "1. Replace the current imports of Chain and Residue with \"from Bio.PDB.Chain import Chain\" and \"from Bio.PDB.Residue import Residue\".\n",
        "2. Remove the logging setup and simply print any log messages to the console.\n",
        "3. Replace the parallel processing with sequential processing to avoid getting an \"OSError: Too many open files\".\n",
        "4. Change the list of pdb_files to instead get all PDB files in the directory that follow the pattern \"**/*unrelaxed_rank_001*.pdb\".\n",
        "5. Change the calculation of average pLDDT to divide by the number of atoms rather than the number of residues.\n",
        "6. Return and save in the CSV both the number of residues and the number of atoms in the interface.\n",
        "7. Change the default distance threshold to 4.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d9bf62680e027cd",
      "metadata": {
        "id": "9d9bf62680e027cd"
      },
      "outputs": [],
      "source": [
        "# Improve AlphaFold-Multimer - discussion\n",
        "improve_alphafold_summaries = load_summaries(discussion_paths=[discussions_phase_to_dir[\"alphafold\"] / \"merged.json\"])\n",
        "print(f\"Number of summaries: {len(improve_alphafold_summaries)}\")\n",
        "\n",
        "run_meeting(\n",
        "    meeting_type=\"individual\",\n",
        "    team_member=computational_biologist,\n",
        "    summaries=improve_alphafold_summaries,\n",
        "    agenda=improve_alphafold_agenda,\n",
        "    save_dir=discussions_phase_to_dir[\"alphafold\"],\n",
        "    save_name=\"improved\",\n",
        "    temperature=CONSISTENT_TEMPERATURE,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ba34f13b0ec3889",
      "metadata": {
        "id": "7ba34f13b0ec3889"
      },
      "source": [
        "### Rosetta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38b7c084b07dd169",
      "metadata": {
        "id": "38b7c084b07dd169"
      },
      "outputs": [],
      "source": [
        "# Rosetta - prompts\n",
        "rosetta_agenda = f\"{background_prompt} {nanobody_prompt} Now you must use Rosetta to calculate the binding energy of nanobody-antigen complexes. You must do this in three parts. First, write a complete RosettaScripts XML file that calculates the binding energy of a nanobody-antigen complex as provided in PDB format, including any necessary preprocessing steps for the complex. Second, write an example command that uses Rosetta to run this RosettaScripts XML file on a given PDB file to calculate the binding energy and save it to a score file. Third, write a complete Python script that takes as input a directory with multiple Rosetta binding energy score files and outputs a single CSV file with the names and scores of each of the individual files in sorted order (highest to lowest score).\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3433242b9472cd28",
      "metadata": {
        "id": "3433242b9472cd28"
      },
      "outputs": [],
      "source": [
        "# Rosetta - discussion\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    concurrent.futures.wait([\n",
        "        executor.submit(\n",
        "            run_meeting,\n",
        "            meeting_type=\"individual\",\n",
        "            team_member=computational_biologist,\n",
        "            agenda=rosetta_agenda,\n",
        "            agenda_rules=CODING_RULES,\n",
        "            save_dir=discussions_phase_to_dir[\"rosetta\"],\n",
        "            save_name=f\"discussion_{iteration_num + 1}\",\n",
        "            temperature=CREATIVE_TEMPERATURE,\n",
        "            num_rounds=num_rounds,\n",
        "        ) for iteration_num in range(num_iterations)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4563b6d0b6116f2a",
      "metadata": {
        "id": "4563b6d0b6116f2a"
      },
      "outputs": [],
      "source": [
        "# Rosetta - merge\n",
        "rosetta_summaries = load_summaries(discussion_paths=list(discussions_phase_to_dir[\"rosetta\"].glob(\"discussion_*.json\")))\n",
        "print(f\"Number of summaries: {len(rosetta_summaries)}\")\n",
        "\n",
        "rosetta_merge_prompt = create_merge_prompt(\n",
        "    agenda=rosetta_agenda,\n",
        "    agenda_rules=CODING_RULES,\n",
        ")\n",
        "\n",
        "run_meeting(\n",
        "    meeting_type=\"individual\",\n",
        "    team_member=computational_biologist,\n",
        "    summaries=rosetta_summaries,\n",
        "    agenda=rosetta_merge_prompt,\n",
        "    save_dir=discussions_phase_to_dir[\"rosetta\"],\n",
        "    save_name=\"merged\",\n",
        "    temperature=CONSISTENT_TEMPERATURE,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4771524f6b0c8270",
      "metadata": {
        "id": "4771524f6b0c8270"
      },
      "source": [
        "### Improve Rosetta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a03ce8ff3dc2c718",
      "metadata": {
        "id": "a03ce8ff3dc2c718"
      },
      "outputs": [],
      "source": [
        "# Improve Rosetta XML - prompts\n",
        "improve_rosetta_xml_agenda = f\"\"\"You previously wrote a RosettaScripts XML file to calculate the binding affinity of a nanobody-antigen complex (see summary). {REWRITE_PROMPT}\n",
        "\n",
        "1. Replace \"ref15.wts\" with \"ref2015.wts\".\n",
        "2. Remove the InterfaceEnergy filter since it is not valid in Rosetta.\n",
        "3. Replace the entire output tag (including any nested tags) with <OUTPUT scorefxn=\"ref15\"/>.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d92fb27857e97f52",
      "metadata": {
        "id": "d92fb27857e97f52"
      },
      "outputs": [],
      "source": [
        "# Improve Rosetta XML - discussion\n",
        "improve_rosetta_xml_summaries = load_summaries(discussion_paths=[discussions_phase_to_dir[\"rosetta\"] / \"merged.json\"])\n",
        "print(f\"Number of summaries: {len(improve_rosetta_xml_summaries)}\")\n",
        "\n",
        "run_meeting(\n",
        "    meeting_type=\"individual\",\n",
        "    team_member=computational_biologist,\n",
        "    summaries=improve_rosetta_xml_summaries,\n",
        "    agenda=improve_rosetta_xml_agenda,\n",
        "    save_dir=discussions_phase_to_dir[\"rosetta\"],\n",
        "    save_name=\"improved_xml\",\n",
        "    temperature=CONSISTENT_TEMPERATURE,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48ed12daeae0cf1e",
      "metadata": {
        "id": "48ed12daeae0cf1e"
      },
      "outputs": [],
      "source": [
        "# Improve Rosetta Python - prompts\n",
        "improve_rosetta_python_agenda = f\"\"\"You previously wrote a Python script to aggregate multiple Rosetta binding energy score files into one CSV file (see summary). {REWRITE_PROMPT}\n",
        "\n",
        "1. Modify the extract_scores_from_file function so that it extracts the dG_separated value from a file of the following form.\n",
        "\n",
        "SEQUENCE:\n",
        "SCORE: total_score complex_normalized           dG_cross dG_cross/dSASAx100 dG_separated dG_separated/dSASAx100 dSASA_hphobic dSASA_int dSASA_polar delta_unsatHbonds dslf_fa13    fa_atr    fa_dun   fa_elec fa_intra_rep fa_intra_sol_xover4              fa_rep              fa_sol hbond_E_fraction hbond_bb_sc hbond_lr_bb    hbond_sc hbond_sr_bb hbonds_int lk_ball_wtd    nres_all    nres_int       omega     p_aa_pp    packstat per_residue_energy_int pro_close rama_prepro         ref    sc_value side1_normalized side1_score side2_normalized side2_score yhh_planarity description\n",
        "SCORE:    -990.807             -2.914            -21.436             -1.857      -21.436                 -1.857       774.274  1154.088     379.813            12.000    -3.867 -1928.622   376.416  -541.777        3.745              54.944             265.303            1052.322            0.053     -84.023    -130.532     -54.069     -46.266      1.000     -41.725     340.000      55.000      39.977     -81.331       0.000                 -2.699     2.349      -6.870     131.513       0.000           -2.236     -51.431           -3.031     -97.008         1.706 KP3_Ty1-G59Y_unrelaxed_rank_001_alphafold2_multimer_v3_model_3_seed_000_0001\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea4287f833216ee9",
      "metadata": {
        "id": "ea4287f833216ee9"
      },
      "outputs": [],
      "source": [
        "# Improve Rosetta Python - discussion\n",
        "improve_rosetta_python_summaries = load_summaries(\n",
        "    discussion_paths=[discussions_phase_to_dir[\"rosetta\"] / \"merged.json\"])\n",
        "print(f\"Number of summaries: {len(improve_rosetta_python_summaries)}\")\n",
        "\n",
        "run_meeting(\n",
        "    meeting_type=\"individual\",\n",
        "    team_member=computational_biologist,\n",
        "    summaries=improve_rosetta_python_summaries,\n",
        "    agenda=improve_rosetta_python_agenda,\n",
        "    save_dir=discussions_phase_to_dir[\"rosetta\"],\n",
        "    save_name=\"improved_python\",\n",
        "    temperature=CONSISTENT_TEMPERATURE,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a050fffc08866b10",
      "metadata": {
        "id": "a050fffc08866b10"
      },
      "source": [
        "## Workflow Design"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c55ec9669eeee9fe",
      "metadata": {
        "id": "c55ec9669eeee9fe"
      },
      "outputs": [],
      "source": [
        "# Workflow design - prompts\n",
        "workflow_design_agenda = f\"{background_prompt} {nanobody_prompt} Your team has built three components of a nanobody design pipeline: ESM, AlphaFold-Multimer, and Rosetta. Each of these three tools can be used to score a nanobody mutation based on how the mutation affects binding to an antigen. Your goal is to start with an existing nanobody and iteratively add mutations to it to improve its binding to the newest variant of the SARS-CoV-2 spike protein, resulting in 24 modified nanobodies with one or more mutations. Please determine how to use ESM, AlphaFold-Multimer, and Rosetta in this iterative design process. An important constraint is that ESM can evaluate all potential mutations to a nanobody in 5 minutes while AlphaFold-Multimer takes 30 minutes per mutation and Rosetta takes five minutes per mutation. The whole iterative process should take no more than a few days to complete. Note that AlphaFold-Multimer must be run before Rosetta on each mutation since Rosetta requires the nanobody-antigen structure predicted by AlphaFold-Multimer. Additionally, note that ESM log-likelihood ratios are generally in the range of 5-10 (higher is better), AlphaFold-Multimer interface pLDDT confidence scores are generally in the range of 60-80 (higher is better), and Rosetta binding energy scores are generally in the range of -20 to -40 (lower is better).\"\n",
        "\n",
        "workflow_design_questions = (\n",
        "    \"In each iteration, what is the order of operations for evaluating mutations with ESM, AlphaFold-Multimer, and Rosetta?\",\n",
        "    \"In each iteration, how many mutations (give a single number) will you evaluate with ESM, AlphaFold-Multimer, and Rosetta?\",\n",
        "    \"At the end of each iteration, how will you weigh the ESM, AlphaFold-Multimer, and/or Rosetta scores (give a formula) to rank the nanobody mutations?\",\n",
        "    \"At the end of each iteration, how many of the top-ranked mutations (give a single number) will you keep for the next round?\",\n",
        "    \"How will you decide how many iterations of mutations to run?\",\n",
        "    \"After all of the iterations are complete, how exactly (step-by-step) will you select the final set of 24 modified nanobodies from across the iterations for experimental validation?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3210bdc6d68bd0bc",
      "metadata": {
        "id": "3210bdc6d68bd0bc"
      },
      "outputs": [],
      "source": [
        "# Workflow design - discussion\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    concurrent.futures.wait([\n",
        "        executor.submit(\n",
        "            run_meeting,\n",
        "            meeting_type=\"individual\",\n",
        "            team_member=principal_investigator,\n",
        "            agenda=workflow_design_agenda,\n",
        "            agenda_questions=workflow_design_questions,\n",
        "            save_dir=discussions_phase_to_dir[\"workflow_design\"],\n",
        "            save_name=f\"discussion_{iteration_num + 1}\",\n",
        "            temperature=CREATIVE_TEMPERATURE,\n",
        "        ) for iteration_num in range(num_iterations)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb4534d4913ecf88",
      "metadata": {
        "id": "cb4534d4913ecf88"
      },
      "outputs": [],
      "source": [
        "# Workflow design - merge\n",
        "workflow_design_summaries = load_summaries(\n",
        "    discussion_paths=list(discussions_phase_to_dir[\"workflow_design\"].glob(\"discussion_*.json\")))\n",
        "print(f\"Number of summaries: {len(workflow_design_summaries)}\")\n",
        "\n",
        "workflow_design_merge_prompt = create_merge_prompt(\n",
        "    agenda=workflow_design_agenda,\n",
        "    agenda_questions=workflow_design_questions,\n",
        ")\n",
        "\n",
        "run_meeting(\n",
        "    meeting_type=\"individual\",\n",
        "    team_member=principal_investigator,\n",
        "    summaries=workflow_design_summaries,\n",
        "    agenda=workflow_design_merge_prompt,\n",
        "    save_dir=discussions_phase_to_dir[\"workflow_design\"],\n",
        "    save_name=\"merged\",\n",
        "    temperature=CONSISTENT_TEMPERATURE,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb5b2c7839b930aa",
      "metadata": {
        "id": "bb5b2c7839b930aa"
      },
      "source": [
        "## Virtual Lab Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74d3a3d37081ed02",
      "metadata": {
        "id": "74d3a3d37081ed02"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "matplotlib.rcParams.update({'font.size': 26})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bebeb39ba3c3b0b",
      "metadata": {
        "id": "8bebeb39ba3c3b0b"
      },
      "outputs": [],
      "source": [
        "figure_dir = Path(\"figures/virtual_lab_analysis\")\n",
        "figure_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "phase_to_agent_to_word_count = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3577d08c72a2aeb",
      "metadata": {
        "id": "3577d08c72a2aeb"
      },
      "outputs": [],
      "source": [
        "# Count words that the human user wrote\n",
        "phase_to_human_words = {\n",
        "    \"team_selection\": [\n",
        "        background_prompt,\n",
        "        principal_investigator.prompt,\n",
        "        scientific_critic.prompt,\n",
        "        team_selection_agenda.replace(f\"{background_prompt} \", \"\"),\n",
        "    ],\n",
        "    \"project_specification\": [\n",
        "        project_specification_agenda.replace(f\"{background_prompt} \", \"\"),\n",
        "        *project_specification_questions,\n",
        "        nanobody_prompt,\n",
        "    ],\n",
        "    \"tools_selection\": [\n",
        "        tools_selection_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
        "        *tools_selection_questions,\n",
        "    ],\n",
        "    \"implementation_agent_selection\": [\n",
        "        implementation_agent_selection_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
        "        *implementation_agent_selection_questions,\n",
        "    ],\n",
        "    \"esm\": [\n",
        "        esm_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
        "        improve_esm_agenda.replace(f\" {REWRITE_PROMPT}\", \"\"),\n",
        "    ],\n",
        "    \"alphafold\": [\n",
        "        alphafold_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
        "        improve_alphafold_agenda.replace(f\" {REWRITE_PROMPT}\", \"\"),\n",
        "    ],\n",
        "    \"rosetta\": [\n",
        "        rosetta_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
        "        improve_rosetta_xml_agenda.replace(f\" {REWRITE_PROMPT}\", \"\"),\n",
        "        improve_rosetta_python_agenda.replace(f\" {REWRITE_PROMPT}\", \"\"),\n",
        "    ],\n",
        "    \"workflow_design\": [\n",
        "        workflow_design_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
        "        *workflow_design_questions,\n",
        "    ],\n",
        "}\n",
        "\n",
        "for phase, human_words in phase_to_human_words.items():\n",
        "    phase_to_agent_to_word_count[phase] = {\"Human Researcher\": len(\" \".join(human_words).split())}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30b622f7378bd3ec",
      "metadata": {
        "id": "30b622f7378bd3ec"
      },
      "outputs": [],
      "source": [
        "# Count words that the LLM agents wrote\n",
        "for phase_name in [\"team_selection\", \"project_specification\", \"tools_selection\",\n",
        "                   \"implementation_agent_selection\", \"esm\", \"alphafold\", \"rosetta\", \"workflow_design\"]:\n",
        "    phase_dir = discussions_phase_to_dir[phase_name]\n",
        "\n",
        "    print(f\"Phase: {phase_name}\")\n",
        "\n",
        "    # Load the text written by each agent\n",
        "    agent_to_text = {}\n",
        "    for path in phase_dir.glob(\"*.json\"):\n",
        "        with open(path) as f:\n",
        "            discussion = json.load(f)\n",
        "\n",
        "        for message in discussion:\n",
        "            agent_to_text.setdefault(message[\"agent\"], []).append(message[\"message\"])\n",
        "\n",
        "    # Count the number of words written by each agent\n",
        "    for agent, text in agent_to_text.items():\n",
        "        if agent == \"User\":\n",
        "            continue\n",
        "\n",
        "        agent_to_text[agent] = \" \".join(text)\n",
        "        word_count = len(agent_to_text[agent].split())\n",
        "        phase_to_agent_to_word_count[phase_name][agent] = word_count\n",
        "\n",
        "# Print words by phase\n",
        "for phase in phase_to_agent_to_word_count:\n",
        "    print(f\"Phase: {phase}\")\n",
        "    for agent, word_count in phase_to_agent_to_word_count[phase].items():\n",
        "        print(f\"Number of words written by {agent}: {word_count:,}\")\n",
        "    print()\n",
        "\n",
        "# Sum word counts across phases\n",
        "agent_to_word_count = {}\n",
        "for phase in phase_to_agent_to_word_count:\n",
        "    for agent, word_count in phase_to_agent_to_word_count[phase].items():\n",
        "        agent_to_word_count[agent] = agent_to_word_count.get(agent, 0) + word_count\n",
        "\n",
        "# Total number of words written by each LLM agent\n",
        "for agent, word_count in agent_to_word_count.items():\n",
        "    print(f\"Total number of words written by {agent}: {word_count:,}\")\n",
        "\n",
        "print()\n",
        "\n",
        "# Total number of words written by all LLM agents\n",
        "total_human_words = sum(\n",
        "    phase_to_agent_to_word_count[phase][\"Human Researcher\"] for phase in phase_to_agent_to_word_count)\n",
        "total_agent_words = sum(word_count for agent, word_count in agent_to_word_count.items() if agent != \"Human Researcher\")\n",
        "\n",
        "print(f\"Total number of words written by Human Researcher: {total_human_words:,}\")\n",
        "print(f\"Total number of words written by all LLM agents: {total_agent_words:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62dd0609f9e7274c",
      "metadata": {
        "id": "62dd0609f9e7274c"
      },
      "outputs": [],
      "source": [
        "agent_to_color = {\n",
        "    agent: sns.color_palette(\"tab10\", n_colors=len(agent_to_word_count))[i]\n",
        "    for i, agent in enumerate(agent_to_word_count)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a00e6cdaa1a1c05",
      "metadata": {
        "id": "3a00e6cdaa1a1c05"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
        "ax.pie(\n",
        "    agent_to_word_count.values(),\n",
        "    labels=agent_to_word_count.keys(),\n",
        "    autopct=\"%1.1f%%\",\n",
        "    colors=[agent_to_color[agent] for agent in agent_to_word_count],\n",
        ")\n",
        "ax.set_title(f\"Words written\")\n",
        "plt.savefig(figure_dir / \"total_words_written.pdf\", bbox_inches=\"tight\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8465196358c50d9e",
      "metadata": {
        "id": "8465196358c50d9e"
      },
      "outputs": [],
      "source": [
        "for phase in phase_to_agent_to_word_count:\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
        "    ax.pie(\n",
        "        phase_to_agent_to_word_count[phase].values(),\n",
        "        labels=phase_to_agent_to_word_count[phase].keys(),\n",
        "        autopct=\"%1.1f%%\",\n",
        "        colors=[agent_to_color[agent] for agent in phase_to_agent_to_word_count[phase]],\n",
        "    )\n",
        "    ax.set_title(f\"Words written in {phase.replace('_', ' ')}\")\n",
        "    plt.savefig(figure_dir / f\"{phase}_words_written.pdf\", bbox_inches=\"tight\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ed39621",
      "metadata": {
        "id": "6ed39621"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da01ffda913de4b2",
      "metadata": {
        "id": "da01ffda913de4b2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
